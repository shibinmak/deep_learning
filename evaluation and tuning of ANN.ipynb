{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/userhadoop/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense,Dropout\n",
    "from tensorflow.contrib.keras.api.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.contrib.keras.api.keras import backend\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['RowNumber','CustomerId','Surname',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.get_dummies(data,['Geography','Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop('Exited',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test =scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ann():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(kernel_initializer='uniform',input_dim=11,activation='relu',units=6))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(kernel_initializer='uniform',activation='relu',units=6))\n",
    "    classifier.add(Dense(kernel_initializer='uniform',activation='sigmoid',units=1))\n",
    "    classifier.compile(optimizer='adam',loss= 'binary_crossentropy',metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eval = KerasClassifier(build_fn=build_ann,batch_size=10,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "5360/5360 [==============================] - 3s 636us/step - loss: 1.8854 - acc: 0.5437\n",
      "4670/5360 [=========================>....] - ETA: 0s - loss: 2.5729 - acc: 0.4927Epoch 2/10\n",
      "5360/5360 [==============================] - 4s 672us/step - loss: 2.0399 - acc: 0.5388\n",
      " 470/5360 [=>............................] - ETA: 2s - loss: 0.5837 - acc: 0.7702Epoch 2/10\n",
      "5360/5360 [==============================] - 4s 699us/step - loss: 2.3159 - acc: 0.5297\n",
      "Epoch 2/10\n",
      "5360/5360 [==============================] - 4s 685us/step - loss: 0.8686 - acc: 0.6666\n",
      "Epoch 2/10\n",
      "5360/5360 [==============================] - 3s 546us/step - loss: 0.5549 - acc: 0.7851\n",
      "4220/5360 [======================>.......] - ETA: 0s - loss: 0.5395 - acc: 0.7953Epoch 3/10\n",
      "5360/5360 [==============================] - 3s 506us/step - loss: 0.5144 - acc: 0.7946\n",
      "5360/5360 [==============================] - 3s 553us/step - loss: 0.5600 - acc: 0.7791\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 3s 618us/step - loss: 0.5373 - acc: 0.7942\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 3s 549us/step - loss: 0.5259 - acc: 0.7860\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 3s 524us/step - loss: 0.5160 - acc: 0.7931\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 3s 567us/step - loss: 0.4852 - acc: 0.7948\n",
      "Epoch 4/10\n",
      "1840/5360 [=========>....................] - ETA: 2s - loss: 0.4954 - acc: 0.7978Epoch 4/10\n",
      "5360/5360 [==============================] - 4s 654us/step - loss: 0.5109 - acc: 0.7938\n",
      "5360/5360 [==============================] - 3s 542us/step - loss: 0.5067 - acc: 0.7858\n",
      "4570/5360 [========================>.....] - ETA: 0s - loss: 0.4712 - acc: 0.7937Epoch 5/10\n",
      "5360/5360 [==============================] - 3s 554us/step - loss: 0.4703 - acc: 0.7950\n",
      "Epoch 5/10\n",
      "5360/5360 [==============================] - 3s 604us/step - loss: 0.4920 - acc: 0.7985\n",
      "  10/5360 [..............................] - ETA: 2s - loss: 0.5481 - acc: 0.7000Epoch 5/10\n",
      "5360/5360 [==============================] - 3s 634us/step - loss: 0.4912 - acc: 0.7961\n",
      "  10/5360 [..............................] - ETA: 1s - loss: 0.4252 - acc: 0.8000Epoch 5/10\n",
      "5360/5360 [==============================] - 4s 656us/step - loss: 0.4963 - acc: 0.7884\n",
      "2990/5360 [===============>..............] - ETA: 1s - loss: 0.4862 - acc: 0.7977Epoch 6/10\n",
      "5360/5360 [==============================] - 3s 579us/step - loss: 0.4627 - acc: 0.7955\n",
      "Epoch 6/10\n",
      "5360/5360 [==============================] - 4s 669us/step - loss: 0.4816 - acc: 0.8000\n",
      "4100/5360 [=====================>........] - ETA: 0s - loss: 0.4818 - acc: 0.7988Epoch 6/10\n",
      "5360/5360 [==============================] - 3s 581us/step - loss: 0.4822 - acc: 0.7966\n",
      "Epoch 6/10\n",
      "5360/5360 [==============================] - 3s 617us/step - loss: 0.4556 - acc: 0.8022\n",
      "2980/5360 [===============>..............] - ETA: 1s - loss: 0.4820 - acc: 0.7940Epoch 7/10\n",
      "5360/5360 [==============================] - 4s 678us/step - loss: 0.4837 - acc: 0.7931\n",
      "4640/5360 [========================>.....] - ETA: 0s - loss: 0.4750 - acc: 0.8009Epoch 7/10\n",
      "5360/5360 [==============================] - 4s 675us/step - loss: 0.4704 - acc: 0.8026\n",
      "4090/5360 [=====================>........] - ETA: 0s - loss: 0.4795 - acc: 0.7944Epoch 7/10\n",
      "5360/5360 [==============================] - 4s 721us/step - loss: 0.4713 - acc: 0.8002\n",
      "2560/5360 [=============>................] - ETA: 1s - loss: 0.4560 - acc: 0.8008Epoch 7/10\n",
      "5360/5360 [==============================] - 4s 737us/step - loss: 0.4514 - acc: 0.8037\n",
      "4950/5360 [==========================>...] - ETA: 0s - loss: 0.4760 - acc: 0.7962Epoch 8/10\n",
      "5360/5360 [==============================] - 4s 728us/step - loss: 0.4791 - acc: 0.7955\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 4s 765us/step - loss: 0.4603 - acc: 0.8080\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 4s 804us/step - loss: 0.4630 - acc: 0.8013\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 4s 761us/step - loss: 0.4473 - acc: 0.8050\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 4s 762us/step - loss: 0.4660 - acc: 0.8002\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 4s 723us/step - loss: 0.4565 - acc: 0.8060\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 4s 656us/step - loss: 0.4528 - acc: 0.8076\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 4s 750us/step - loss: 0.4381 - acc: 0.8121\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 4s 800us/step - loss: 0.4607 - acc: 0.8028\n",
      "3870/5360 [====================>.........] - ETA: 1s - loss: 0.4363 - acc: 0.8173Epoch 10/10\n",
      "5360/5360 [==============================] - 4s 748us/step - loss: 0.4487 - acc: 0.8119\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 4s 757us/step - loss: 0.4426 - acc: 0.8151\n",
      "2520/5360 [=============>................] - ETA: 1s - loss: 0.4317 - acc: 0.8190Epoch 10/10\n",
      "5360/5360 [==============================] - 4s 700us/step - loss: 0.4316 - acc: 0.8177\n",
      "1340/1340 [==============================] - 1s 401us/steps: 0.4443 - acc: 0.81\n",
      "5360/5360 [==============================] - 4s 719us/step - loss: 0.4411 - acc: 0.8160\n",
      "5360/5360 [==============================] - 4s 810us/step - loss: 0.4512 - acc: 0.8075\n",
      "1340/1340 [==============================] - 1s 418us/steps: 0.4371 - acc\n",
      "1340/1340 [==============================] - 1s 380us/steps: 0.4361 - acc: 0.\n",
      "5360/5360 [==============================] - 4s 714us/step - loss: 0.4327 - acc: 0.8179\n",
      "1340/1340 [==============================] - 0s 325us/step\n",
      "Epoch 1/10\n",
      "5360/5360 [==============================] - 2s 306us/step - loss: 1.8354 - acc: 0.5698\n",
      "Epoch 2/10\n",
      "5360/5360 [==============================] - 1s 201us/step - loss: 0.5375 - acc: 0.7905\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 1s 208us/step - loss: 0.5176 - acc: 0.7910\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 190us/step - loss: 0.5042 - acc: 0.7916\n",
      "Epoch 5/10\n",
      "5360/5360 [==============================] - 1s 187us/step - loss: 0.4941 - acc: 0.7910\n",
      "Epoch 6/10\n",
      "5360/5360 [==============================] - 1s 192us/step - loss: 0.4844 - acc: 0.7899\n",
      "Epoch 7/10\n",
      "5360/5360 [==============================] - 1s 219us/step - loss: 0.4756 - acc: 0.7899\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 1s 247us/step - loss: 0.4692 - acc: 0.7912\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 1s 208us/step - loss: 0.4591 - acc: 0.7944\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 1s 214us/step - loss: 0.4543 - acc: 0.7965\n",
      "1340/1340 [==============================] - 0s 183us/step\n"
     ]
    }
   ],
   "source": [
    "accuracy= cross_val_score(estimator=classifier_eval,X=X_train,y=y_train,cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153731302094103"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012295101591851335"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80820895, 0.80895522, 0.83955223, 0.80671641, 0.81343283])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(kernel_initializer='uniform',input_dim=11,activation='relu',units=6))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(kernel_initializer='uniform',activation='relu',units=6))\n",
    "    classifier.add(Dense(kernel_initializer='uniform',activation='sigmoid',units=1))\n",
    "    classifier.compile(optimizer,loss= 'binary_crossentropy',metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_optimizer = KerasClassifier(build_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter ={'optimizer':['adam'],'batch_size':[20,30],'epochs':[5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=classifier_optimizer,param_grid=parameter,scoring='accuracy',cv=5, n_jobs=-1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] optimizer=adam, batch_size=20, epochs=5 .........................\n",
      "[CV] optimizer=adam, batch_size=20, epochs=5 .........................\n",
      "[CV] optimizer=adam, batch_size=20, epochs=5 .........................\n",
      "[CV] optimizer=adam, batch_size=20, epochs=5 .........................\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "5360/5360 [==============================] - 2s 364us/step - loss: 2.8850 - acc: 0.4159\n",
      "Epoch 2/5\n",
      "5360/5360 [==============================] - 2s 399us/step - loss: 2.4436 - acc: 0.4420\n",
      "Epoch 2/5\n",
      "5360/5360 [==============================] - 2s 403us/step - loss: 2.1796 - acc: 0.4672\n",
      "Epoch 2/5\n",
      "5360/5360 [==============================] - 2s 393us/step - loss: 1.6806 - acc: 0.5118\n",
      "Epoch 2/5\n",
      "5360/5360 [==============================] - 2s 308us/step - loss: 0.7415 - acc: 0.6713\n",
      "Epoch 3/5\n",
      "5360/5360 [==============================] - 2s 282us/step - loss: 0.7711 - acc: 0.6396\n",
      "4920/5360 [==========================>...] - ETA: 0s - loss: 0.6524 - acc: 0.7228Epoch 3/5\n",
      "5360/5360 [==============================] - 1s 279us/step - loss: 0.6460 - acc: 0.7285\n",
      "Epoch 3/5\n",
      "5360/5360 [==============================] - 2s 295us/step - loss: 0.5363 - acc: 0.7909\n",
      "Epoch 3/5\n",
      "5360/5360 [==============================] - 1s 254us/step - loss: 0.5530 - acc: 0.7938\n",
      "Epoch 4/5\n",
      "5360/5360 [==============================] - 2s 312us/step - loss: 0.5479 - acc: 0.7937\n",
      "Epoch 4/5\n",
      "5360/5360 [==============================] - 1s 262us/step - loss: 0.5055 - acc: 0.7937\n",
      "Epoch 4/5\n",
      "5360/5360 [==============================] - 2s 295us/step - loss: 0.5618 - acc: 0.7869\n",
      " 240/5360 [>.............................] - ETA: 1s - loss: 0.5215 - acc: 0.7750Epoch 4/5\n",
      "5360/5360 [==============================] - 2s 325us/step - loss: 0.5274 - acc: 0.7948\n",
      "Epoch 5/5\n",
      "5360/5360 [==============================] - 2s 295us/step - loss: 0.5262 - acc: 0.7950\n",
      "Epoch 5/5\n",
      "5360/5360 [==============================] - 2s 293us/step - loss: 0.4895 - acc: 0.7965\n",
      "4780/5360 [=========================>....] - ETA: 0s - loss: 0.5414 - acc: 0.7872Epoch 5/5\n",
      "5360/5360 [==============================] - 2s 309us/step - loss: 0.5412 - acc: 0.7879\n",
      "Epoch 5/5\n",
      "5360/5360 [==============================] - 1s 255us/step - loss: 0.5085 - acc: 0.7948\n",
      "5360/5360 [==============================] - 1s 255us/step - loss: 0.5088 - acc: 0.7950\n",
      "5360/5360 [==============================] - 2s 300us/step - loss: 0.4806 - acc: 0.7961\n",
      "5360/5360 [==============================] - 1s 279us/step - loss: 0.5254 - acc: 0.7894\n",
      "[CV] .......... optimizer=adam, batch_size=20, epochs=5, total=   9.5s\n",
      "[CV] optimizer=adam, batch_size=20, epochs=5 .........................\n",
      "[CV] .......... optimizer=adam, batch_size=20, epochs=5, total=   9.5s\n",
      "[CV] optimizer=adam, batch_size=20, epochs=10 ........................\n",
      "[CV] .......... optimizer=adam, batch_size=20, epochs=5, total=   9.9s\n",
      "[CV] optimizer=adam, batch_size=20, epochs=10 ........................\n",
      "[CV] .......... optimizer=adam, batch_size=20, epochs=5, total=  10.0s\n",
      "[CV] optimizer=adam, batch_size=20, epochs=10 ........................\n",
      "Epoch 1/5\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "  20/5360 [..............................] - ETA: 4:16 - loss: 8.8157 - acc: 0.1000Epoch 1/10\n",
      "5360/5360 [==============================] - 2s 444us/step - loss: 2.1486 - acc: 0.4819\n",
      "2940/5360 [===============>..............] - ETA: 1s - loss: 3.3265 - acc: 0.4286Epoch 2/5\n",
      "5360/5360 [==============================] - 3s 490us/step - loss: 3.0024 - acc: 0.4364\n",
      "1440/5360 [=======>......................] - ETA: 1s - loss: 0.6478 - acc: 0.7153Epoch 2/10\n",
      "5360/5360 [==============================] - 3s 474us/step - loss: 2.4954 - acc: 0.4720\n",
      "2860/5360 [===============>..............] - ETA: 0s - loss: 0.6075 - acc: 0.7500Epoch 2/10\n",
      "5360/5360 [==============================] - 2s 451us/step - loss: 1.5077 - acc: 0.4931\n",
      "2320/5360 [===========>..................] - ETA: 0s - loss: 1.0611 - acc: 0.5418Epoch 2/10\n",
      "5360/5360 [==============================] - 2s 286us/step - loss: 0.5774 - acc: 0.7675\n",
      "3600/5360 [===================>..........] - ETA: 0s - loss: 0.9329 - acc: 0.5819Epoch 3/5\n",
      "5360/5360 [==============================] - 2s 298us/step - loss: 0.8226 - acc: 0.6418\n",
      "3040/5360 [================>.............] - ETA: 0s - loss: 0.6229 - acc: 0.7349Epoch 3/10\n",
      "5360/5360 [==============================] - 2s 362us/step - loss: 0.5843 - acc: 0.7621\n",
      "5360/5360 [==============================] - 2s 317us/step - loss: 0.5758 - acc: 0.7668\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 1s 265us/step - loss: 0.5319 - acc: 0.7909\n",
      "Epoch 4/5\n",
      "5360/5360 [==============================] - 2s 298us/step - loss: 0.5529 - acc: 0.7944\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 274us/step - loss: 0.5180 - acc: 0.7948\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 279us/step - loss: 0.5274 - acc: 0.7866\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 2s 313us/step - loss: 0.5151 - acc: 0.7881\n",
      "Epoch 5/5\n",
      "5360/5360 [==============================] - 2s 325us/step - loss: 0.5323 - acc: 0.7948\n",
      "3880/5360 [====================>.........] - ETA: 0s - loss: 0.5119 - acc: 0.7838Epoch 5/10\n",
      "5360/5360 [==============================] - 2s 336us/step - loss: 0.5059 - acc: 0.7899\n",
      "Epoch 5/10\n",
      "5360/5360 [==============================] - 2s 358us/step - loss: 0.5017 - acc: 0.7933\n",
      "3940/5360 [=====================>........] - ETA: 0s - loss: 0.5039 - acc: 0.7906Epoch 5/10\n",
      "5360/5360 [==============================] - 2s 392us/step - loss: 0.5054 - acc: 0.7888\n",
      "5360/5360 [==============================] - 2s 430us/step - loss: 0.5176 - acc: 0.7948\n",
      "4280/5360 [======================>.......] - ETA: 0s - loss: 0.4955 - acc: 0.7881Epoch 6/10\n",
      "3480/5360 [==================>...........] - ETA: 0s - loss: 0.4925 - acc: 0.7940[CV] .......... optimizer=adam, batch_size=20, epochs=5, total=  11.0s\n",
      "4400/5360 [=======================>......] - ETA: 0s - loss: 0.4953 - acc: 0.7882[CV] optimizer=adam, batch_size=20, epochs=10 ........................\n",
      "5360/5360 [==============================] - 2s 403us/step - loss: 0.4924 - acc: 0.7910\n",
      "4500/5360 [========================>.....] - ETA: 0s - loss: 0.4912 - acc: 0.7944Epoch 6/10\n",
      "5360/5360 [==============================] - 2s 462us/step - loss: 0.4920 - acc: 0.7938\n",
      "Epoch 6/10\n",
      "5360/5360 [==============================] - 2s 402us/step - loss: 0.5060 - acc: 0.7946\n",
      "3140/5360 [================>.............] - ETA: 1s - loss: 0.4837 - acc: 0.7882Epoch 7/10\n",
      "5360/5360 [==============================] - 2s 328us/step - loss: 0.4833 - acc: 0.7965\n",
      "Epoch 1/10\n",
      "4760/5360 [=========================>....] - ETA: 0s - loss: 0.4812 - acc: 0.7901Epoch 7/10\n",
      "5360/5360 [==============================] - 2s 431us/step - loss: 0.4835 - acc: 0.7897\n",
      "2540/5360 [=============>................] - ETA: 0s - loss: 0.4787 - acc: 0.8102Epoch 7/10\n",
      "5360/5360 [==============================] - 1s 226us/step - loss: 0.4954 - acc: 0.7948\n",
      "3060/5360 [================>.............] - ETA: 0s - loss: 0.4654 - acc: 0.8033Epoch 8/10\n",
      "5360/5360 [==============================] - 2s 280us/step - loss: 0.4790 - acc: 0.7933\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 1s 263us/step - loss: 0.4791 - acc: 0.7892\n",
      "1660/5360 [========>.....................] - ETA: 3s - loss: 4.5110 - acc: 0.4054Epoch 8/10\n",
      "5360/5360 [==============================] - 2s 303us/step - loss: 0.4874 - acc: 0.7957\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 3s 489us/step - loss: 2.9434 - acc: 0.4608\n",
      "4160/5360 [======================>.......] - ETA: 0s - loss: 0.4699 - acc: 0.8005Epoch 2/10\n",
      "5360/5360 [==============================] - 1s 219us/step - loss: 0.4738 - acc: 0.7924\n",
      " 560/5360 [==>...........................] - ETA: 1s - loss: 0.9282 - acc: 0.5857Epoch 9/10\n",
      "5360/5360 [==============================] - 1s 255us/step - loss: 0.4778 - acc: 0.7946\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 1s 258us/step - loss: 0.4804 - acc: 0.7955\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 2s 284us/step - loss: 0.6240 - acc: 0.7422\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 1s 279us/step - loss: 0.4708 - acc: 0.7877\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360/5360 [==============================] - 2s 293us/step - loss: 0.4717 - acc: 0.7968\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 2s 290us/step - loss: 0.4735 - acc: 0.7963\n",
      "5360/5360 [==============================] - 1s 266us/step - loss: 0.5373 - acc: 0.7897\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 252us/step - loss: 0.4680 - acc: 0.7931\n",
      "5360/5360 [==============================] - 1s 254us/step - loss: 0.4681 - acc: 0.8000\n",
      "1720/5360 [========>.....................] - ETA: 0s - loss: 0.5228 - acc: 0.7930[CV] ......... optimizer=adam, batch_size=20, epochs=10, total=  19.8s\n",
      "[CV] optimizer=adam, batch_size=20, epochs=10 ........................\n",
      "3220/5360 [=================>............] - ETA: 0s - loss: 0.5199 - acc: 0.7932[CV] ......... optimizer=adam, batch_size=20, epochs=10, total=  19.7s\n",
      "3500/5360 [==================>...........] - ETA: 0s - loss: 0.5207 - acc: 0.7917[CV] optimizer=adam, batch_size=30, epochs=5 .........................\n",
      "3780/5360 [====================>.........] - ETA: 0s - loss: 0.5191 - acc: 0.7921[CV] ......... optimizer=adam, batch_size=20, epochs=10, total=  20.1s\n",
      "[CV] optimizer=adam, batch_size=30, epochs=5 .........................\n",
      "5360/5360 [==============================] - 1s 257us/step - loss: 0.5201 - acc: 0.7897\n",
      "Epoch 5/10\n",
      "1860/5360 [=========>....................] - ETA: 1s - loss: 0.5088 - acc: 0.7914Epoch 1/10\n",
      "2700/5360 [==============>...............] - ETA: 0s - loss: 0.5088 - acc: 0.7889Epoch 1/5\n",
      "3300/5360 [=================>............] - ETA: 0s - loss: 0.5079 - acc: 0.7921Epoch 1/5\n",
      "5360/5360 [==============================] - 2s 307us/step - loss: 0.5018 - acc: 0.7944\n",
      "Epoch 6/10\n",
      "5360/5360 [==============================] - 2s 455us/step - loss: 3.8652 - acc: 0.4293\n",
      "Epoch 2/5\n",
      "5360/5360 [==============================] - 3s 526us/step - loss: 2.5131 - acc: 0.4562\n",
      "4020/5360 [=====================>........] - ETA: 0s - loss: 3.1303 - acc: 0.4194Epoch 2/10\n",
      "5360/5360 [==============================] - 2s 400us/step - loss: 0.4910 - acc: 0.7961\n",
      "5130/5360 [===========================>..] - ETA: 0s - loss: 2.8229 - acc: 0.4370Epoch 7/10\n",
      "5360/5360 [==============================] - 3s 527us/step - loss: 2.7696 - acc: 0.4369\n",
      "1360/5360 [======>.......................] - ETA: 1s - loss: 0.6915 - acc: 0.6875Epoch 2/5\n",
      "5360/5360 [==============================] - 1s 255us/step - loss: 1.6080 - acc: 0.5265\n",
      "Epoch 3/5\n",
      "5360/5360 [==============================] - 1s 213us/step - loss: 0.7459 - acc: 0.6856\n",
      "2280/5360 [===========>..................] - ETA: 0s - loss: 0.9078 - acc: 0.5943Epoch 3/5\n",
      "5360/5360 [==============================] - 2s 321us/step - loss: 0.6114 - acc: 0.7601\n",
      "4020/5360 [=====================>........] - ETA: 0s - loss: 0.4879 - acc: 0.7960Epoch 3/10\n",
      "5360/5360 [==============================] - 2s 313us/step - loss: 0.4831 - acc: 0.7976\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 1s 199us/step - loss: 0.8196 - acc: 0.6295\n",
      "Epoch 4/5\n",
      "5360/5360 [==============================] - 1s 195us/step - loss: 0.5567 - acc: 0.7918\n",
      "1540/5360 [=======>......................] - ETA: 1s - loss: 0.4729 - acc: 0.8039Epoch 4/5\n",
      "5360/5360 [==============================] - 1s 169us/step - loss: 0.6223 - acc: 0.7231\n",
      "3740/5360 [===================>..........] - ETA: 0s - loss: 0.4802 - acc: 0.7965Epoch 5/5\n",
      "5360/5360 [==============================] - 2s 337us/step - loss: 0.5489 - acc: 0.7909\n",
      "4140/5360 [======================>.......] - ETA: 0s - loss: 0.5364 - acc: 0.7889Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 235us/step - loss: 0.5316 - acc: 0.7925\n",
      "Epoch 5/5\n",
      "5360/5360 [==============================] - 2s 376us/step - loss: 0.4775 - acc: 0.7981\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 2s 312us/step - loss: 0.5589 - acc: 0.7909\n",
      "5360/5360 [==============================] - 1s 209us/step - loss: 0.5166 - acc: 0.7931\n",
      "5360/5360 [==============================] - 2s 338us/step - loss: 0.5282 - acc: 0.7905\n",
      "3460/5360 [==================>...........] - ETA: 0s - loss: 0.4709 - acc: 0.8012Epoch 5/10\n",
      "4000/5360 [=====================>........] - ETA: 0s - loss: 0.4727 - acc: 0.7993[CV] .......... optimizer=adam, batch_size=30, epochs=5, total=   9.4s\n",
      " 440/5360 [=>............................] - ETA: 2s - loss: 0.5023 - acc: 0.8114[CV] optimizer=adam, batch_size=30, epochs=5 .........................\n",
      "4540/5360 [========================>.....] - ETA: 0s - loss: 0.4709 - acc: 0.8004[CV] .......... optimizer=adam, batch_size=30, epochs=5, total=   9.4s\n",
      "[CV] optimizer=adam, batch_size=30, epochs=5 .........................\n",
      "5360/5360 [==============================] - 2s 373us/step - loss: 0.4729 - acc: 0.8009\n",
      "1880/5360 [=========>....................] - ETA: 1s - loss: 0.5060 - acc: 0.8016Epoch 10/10\n",
      "5360/5360 [==============================] - 2s 407us/step - loss: 0.5125 - acc: 0.7916\n",
      "Epoch 6/10\n",
      " 340/5360 [>.............................] - ETA: 1s - loss: 0.5371 - acc: 0.7676Epoch 1/5\n",
      "5060/5360 [===========================>..] - ETA: 0s - loss: 0.4613 - acc: 0.8016Epoch 1/5\n",
      "5360/5360 [==============================] - 2s 383us/step - loss: 0.4602 - acc: 0.8034\n",
      "4940/5360 [==========================>...] - ETA: 0s - loss: 0.4997 - acc: 0.79476[CV] ......... optimizer=adam, batch_size=20, epochs=10, total=  21.6s\n",
      " 360/5360 [=>............................] - ETA: 18s - loss: 4.9073 - acc: 0.4194 [CV] optimizer=adam, batch_size=30, epochs=5 .........................\n",
      "5360/5360 [==============================] - 2s 296us/step - loss: 0.5004 - acc: 0.7944\n",
      "Epoch 7/10\n",
      "5360/5360 [==============================] - 2s 460us/step - loss: 3.9723 - acc: 0.4493\n",
      "3200/5360 [================>.............] - ETA: 0s - loss: 0.4898 - acc: 0.7978Epoch 2/5\n",
      "5360/5360 [==============================] - 3s 486us/step - loss: 3.5418 - acc: 0.4071\n",
      "Epoch 2/5\n",
      "3030/5360 [===============>..............] - ETA: 0s - loss: 2.1044 - acc: 0.5297Epoch 1/5\n",
      "5360/5360 [==============================] - 2s 287us/step - loss: 0.4911 - acc: 0.7955\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 1s 183us/step - loss: 1.7390 - acc: 0.5425\n",
      "2460/5360 [============>.................] - ETA: 0s - loss: 1.4959 - acc: 0.4959Epoch 3/5\n",
      "5360/5360 [==============================] - 1s 199us/step - loss: 1.1163 - acc: 0.5724\n",
      "Epoch 3/5\n",
      "5360/5360 [==============================] - 1s 182us/step - loss: 0.7872 - acc: 0.6586\n",
      "Epoch 4/5\n",
      "5360/5360 [==============================] - 2s 299us/step - loss: 0.4810 - acc: 0.7935\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 2s 319us/step - loss: 2.2040 - acc: 0.4071\n",
      "Epoch 2/5\n",
      "5360/5360 [==============================] - 1s 149us/step - loss: 0.5796 - acc: 0.7759\n",
      "2940/5360 [===============>..............] - ETA: 0s - loss: 0.5782 - acc: 0.7748Epoch 4/5\n",
      "5360/5360 [==============================] - 1s 158us/step - loss: 0.5721 - acc: 0.7772\n",
      "Epoch 5/5\n",
      "5360/5360 [==============================] - 1s 158us/step - loss: 0.6890 - acc: 0.6823\n",
      "4230/5360 [======================>.......] - ETA: 0s - loss: 0.5457 - acc: 0.7941Epoch 3/5\n",
      "5360/5360 [==============================] - 1s 177us/step - loss: 0.5469 - acc: 0.7925\n",
      "Epoch 5/5\n",
      "5360/5360 [==============================] - 1s 269us/step - loss: 0.4729 - acc: 0.7979\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 1s 173us/step - loss: 0.5481 - acc: 0.7871\n",
      "5360/5360 [==============================] - 1s 173us/step - loss: 0.5499 - acc: 0.7897\n",
      "1740/5360 [========>.....................] - ETA: 0s - loss: 0.4629 - acc: 0.8040Epoch 4/5\n",
      "5360/5360 [==============================] - 1s 162us/step - loss: 0.5345 - acc: 0.7879\n",
      "1290/5360 [======>.......................] - ETA: 0s - loss: 0.5163 - acc: 0.8062[CV] .......... optimizer=adam, batch_size=30, epochs=5, total=   8.6s\n",
      "2740/5360 [==============>...............] - ETA: 0s - loss: 0.4771 - acc: 0.7945[CV] optimizer=adam, batch_size=30, epochs=10 ........................\n",
      "3870/5360 [====================>.........] - ETA: 0s - loss: 0.5313 - acc: 0.7953[CV] .......... optimizer=adam, batch_size=30, epochs=5, total=   8.9s\n",
      "4460/5360 [=======================>......] - ETA: 0s - loss: 0.4744 - acc: 0.7917[CV] optimizer=adam, batch_size=30, epochs=10 ........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5360/5360 [==============================] - 1s 174us/step - loss: 0.5337 - acc: 0.7907\n",
      "5080/5360 [===========================>..] - ETA: 0s - loss: 0.4688 - acc: 0.7969Epoch 5/5\n",
      "5360/5360 [==============================] - 1s 268us/step - loss: 0.4656 - acc: 0.7993\n",
      "3510/5360 [==================>...........] - ETA: 0s - loss: 0.5235 - acc: 0.7872[CV] ......... optimizer=adam, batch_size=20, epochs=10, total=  20.0s\n",
      "[CV] optimizer=adam, batch_size=30, epochs=10 ........................\n",
      "4350/5360 [=======================>......] - ETA: 0s - loss: 0.5160 - acc: 0.7924Epoch 1/10\n",
      "5360/5360 [==============================] - 1s 223us/step - loss: 0.5189 - acc: 0.7901\n",
      "Epoch 1/10\n",
      "[CV] .......... optimizer=adam, batch_size=30, epochs=5, total=   7.7s\n",
      "[CV] optimizer=adam, batch_size=30, epochs=10 ........................\n",
      "  30/5360 [..............................] - ETA: 3:09 - loss: 4.5681 - acc: 0.3333Epoch 1/10\n",
      "5360/5360 [==============================] - 2s 380us/step - loss: 3.7212 - acc: 0.4121\n",
      "Epoch 2/10\n",
      "4530/5360 [========================>.....] - ETA: 0s - loss: 2.9132 - acc: 0.4448Epoch 1/10\n",
      "5360/5360 [==============================] - 2s 351us/step - loss: 2.7062 - acc: 0.4519\n",
      "2550/5360 [=============>................] - ETA: 0s - loss: 1.7563 - acc: 0.4988Epoch 2/10\n",
      "5360/5360 [==============================] - 1s 146us/step - loss: 1.3734 - acc: 0.5375\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 1s 164us/step - loss: 0.9396 - acc: 0.6047\n",
      "2970/5360 [===============>..............] - ETA: 0s - loss: 0.6705 - acc: 0.6960Epoch 3/10\n",
      "5360/5360 [==============================] - 2s 318us/step - loss: 3.0249 - acc: 0.4039\n",
      "  30/5360 [..............................] - ETA: 0s - loss: 0.6287 - acc: 0.76672 Epoch 2/10\n",
      "5360/5360 [==============================] - 1s 152us/step - loss: 0.6279 - acc: 0.7362\n",
      "2100/5360 [==========>...................] - ETA: 0s - loss: 1.4111 - acc: 0.4881Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 149us/step - loss: 0.5965 - acc: 0.7821\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 2s 344us/step - loss: 2.0868 - acc: 0.4271\n",
      "Epoch 2/10\n",
      "5360/5360 [==============================] - 1s 157us/step - loss: 1.0993 - acc: 0.5362\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 1s 161us/step - loss: 0.5549 - acc: 0.7924\n",
      "Epoch 5/10\n",
      "5360/5360 [==============================] - 1s 184us/step - loss: 0.5671 - acc: 0.7944\n",
      "Epoch 5/10\n",
      "5360/5360 [==============================] - 1s 175us/step - loss: 0.6090 - acc: 0.7425\n",
      "5220/5360 [============================>.] - ETA: 0s - loss: 0.7615 - acc: 0.6481Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 184us/step - loss: 0.7562 - acc: 0.6528\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 1s 186us/step - loss: 0.5353 - acc: 0.7955\n",
      "2190/5360 [===========>..................] - ETA: 0s - loss: 0.5541 - acc: 0.7913Epoch 6/10\n",
      "5360/5360 [==============================] - 1s 173us/step - loss: 0.5536 - acc: 0.7873\n",
      "Epoch 5/10\n",
      "5360/5360 [==============================] - 1s 175us/step - loss: 0.5700 - acc: 0.7942\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 1s 201us/step - loss: 0.5475 - acc: 0.7942\n",
      "3360/5360 [=================>............] - ETA: 0s - loss: 0.5230 - acc: 0.7937Epoch 6/10\n",
      "5360/5360 [==============================] - 1s 191us/step - loss: 0.5220 - acc: 0.7938\n",
      "2040/5360 [==========>...................] - ETA: 0s - loss: 0.5296 - acc: 0.7985Epoch 7/10\n",
      "5360/5360 [==============================] - 1s 179us/step - loss: 0.5379 - acc: 0.7881\n",
      "Epoch 6/10\n",
      "5360/5360 [==============================] - 1s 186us/step - loss: 0.5465 - acc: 0.7935\n",
      "3060/5360 [================>.............] - ETA: 0s - loss: 0.5103 - acc: 0.7980Epoch 5/10\n",
      "5360/5360 [==============================] - 1s 184us/step - loss: 0.5285 - acc: 0.7944\n",
      "Epoch 7/10\n",
      "5360/5360 [==============================] - 1s 205us/step - loss: 0.5122 - acc: 0.7959\n",
      "2640/5360 [=============>................] - ETA: 0s - loss: 0.5161 - acc: 0.7970Epoch 8/10\n",
      "5360/5360 [==============================] - 1s 214us/step - loss: 0.5227 - acc: 0.7890\n",
      "Epoch 7/10\n",
      "5360/5360 [==============================] - 1s 216us/step - loss: 0.5307 - acc: 0.7938\n",
      "4350/5360 [=======================>......] - ETA: 0s - loss: 0.5092 - acc: 0.7984Epoch 6/10\n",
      "5360/5360 [==============================] - 1s 239us/step - loss: 0.5109 - acc: 0.7955\n",
      " 630/5360 [==>...........................] - ETA: 1s - loss: 0.5165 - acc: 0.8032Epoch 8/10\n",
      "5360/5360 [==============================] - 1s 254us/step - loss: 0.5048 - acc: 0.7948\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 1s 249us/step - loss: 0.5113 - acc: 0.7897\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 2s 311us/step - loss: 0.5183 - acc: 0.7937\n",
      "2070/5360 [==========>...................] - ETA: 1s - loss: 0.5145 - acc: 0.7778Epoch 7/10\n",
      "5360/5360 [==============================] - 2s 313us/step - loss: 0.4988 - acc: 0.7933\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 2s 354us/step - loss: 0.4949 - acc: 0.7950\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 2s 340us/step - loss: 0.5009 - acc: 0.7905\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 2s 318us/step - loss: 0.5056 - acc: 0.7965\n",
      " 930/5360 [====>.........................] - ETA: 1s - loss: 0.4716 - acc: 0.8032Epoch 8/10\n",
      "5360/5360 [==============================] - 2s 297us/step - loss: 0.4886 - acc: 0.7929\n",
      " 210/5360 [>.............................] - ETA: 1s - loss: 0.4757 - acc: 0.8095Epoch 10/10\n",
      "5360/5360 [==============================] - 2s 330us/step - loss: 0.4887 - acc: 0.7972\n",
      "5360/5360 [==============================] - 2s 311us/step - loss: 0.4934 - acc: 0.7903\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 1s 252us/step - loss: 0.4969 - acc: 0.7957\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 1s 259us/step - loss: 0.4788 - acc: 0.7966\n",
      "1920/5360 [=========>....................] - ETA: 0s - loss: 0.4777 - acc: 0.8016[CV] ......... optimizer=adam, batch_size=30, epochs=10, total=  14.9s\n",
      "[CV] optimizer=adam, batch_size=30, epochs=10 ........................\n",
      "3390/5360 [=================>............] - ETA: 0s - loss: 0.4859 - acc: 0.7985[CV] ......... optimizer=adam, batch_size=30, epochs=10, total=  14.8s\n",
      "5360/5360 [==============================] - 1s 216us/step - loss: 0.4855 - acc: 0.7927\n",
      "5360/5360 [==============================] - 1s 224us/step - loss: 0.4875 - acc: 0.7978\n",
      "Epoch 10/10\n",
      "2370/5360 [============>.................] - ETA: 0s - loss: 0.4716 - acc: 0.8046[CV] ......... optimizer=adam, batch_size=30, epochs=10, total=  14.8s\n",
      "5360/5360 [==============================] - 1s 132us/step - loss: 0.4772 - acc: 0.7994\n",
      "Epoch 1/10\n",
      "[CV] ......... optimizer=adam, batch_size=30, epochs=10, total=  14.4s\n",
      "5360/5360 [==============================] - 1s 231us/step - loss: 3.7497 - acc: 0.4211\n",
      "Epoch 2/10\n",
      "5360/5360 [==============================] - 0s 73us/step - loss: 1.1929 - acc: 0.5748\n",
      "Epoch 3/10\n",
      "5360/5360 [==============================] - 0s 66us/step - loss: 0.5851 - acc: 0.7677\n",
      "Epoch 4/10\n",
      "5360/5360 [==============================] - 0s 66us/step - loss: 0.5484 - acc: 0.7864\n",
      "Epoch 5/10\n",
      "5360/5360 [==============================] - 0s 64us/step - loss: 0.5309 - acc: 0.7854\n",
      "Epoch 6/10\n",
      "5360/5360 [==============================] - 0s 62us/step - loss: 0.5152 - acc: 0.7924\n",
      "Epoch 7/10\n",
      "5360/5360 [==============================] - 0s 69us/step - loss: 0.5053 - acc: 0.7925\n",
      "Epoch 8/10\n",
      "5360/5360 [==============================] - 0s 85us/step - loss: 0.4988 - acc: 0.7901\n",
      "Epoch 9/10\n",
      "5360/5360 [==============================] - 0s 82us/step - loss: 0.4934 - acc: 0.7925\n",
      "Epoch 10/10\n",
      "5360/5360 [==============================] - 0s 68us/step - loss: 0.4882 - acc: 0.7933\n",
      "[CV] ......... optimizer=adam, batch_size=30, epochs=10, total=   6.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6700/6700 [==============================] - 1s 195us/step - loss: 1.5325 - acc: 0.5516\n",
      "Epoch 2/10\n",
      "6700/6700 [==============================] - 1s 161us/step - loss: 0.5544 - acc: 0.7893\n",
      "Epoch 3/10\n",
      "6700/6700 [==============================] - 1s 157us/step - loss: 0.5210 - acc: 0.7916\n",
      "Epoch 4/10\n",
      "6700/6700 [==============================] - 1s 95us/step - loss: 0.4991 - acc: 0.7915\n",
      "Epoch 5/10\n",
      "6700/6700 [==============================] - 1s 99us/step - loss: 0.4851 - acc: 0.7904\n",
      "Epoch 6/10\n",
      "6700/6700 [==============================] - 1s 94us/step - loss: 0.4793 - acc: 0.7906\n",
      "Epoch 7/10\n",
      "6700/6700 [==============================] - 1s 84us/step - loss: 0.4743 - acc: 0.7910\n",
      "Epoch 8/10\n",
      "6700/6700 [==============================] - 1s 84us/step - loss: 0.4689 - acc: 0.7934\n",
      "Epoch 9/10\n",
      "6700/6700 [==============================] - 1s 95us/step - loss: 0.4647 - acc: 0.7955\n",
      "Epoch 10/10\n",
      "6700/6700 [==============================] - 1s 94us/step - loss: 0.4624 - acc: 0.7982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=<tensorflow.python.keras._impl.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fc7229e99b0>,\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'optimizer': ['adam'], 'batch_size': [20, 30], 'epochs': [5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 30, 'epochs': 10, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.wrappers.scikit_learn.KerasClassifier at 0x7f5ce4b0c4e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
